{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"},"mipasa-version":7,"mps_autorun_after_files_updated":false,"mps_environment":"ezkl","mps_gpu":false,"mps_memory":4294967296},"cells":[{"id":"cf69bb3f-94e6-4dba-92cd-ce08df117d67","metadata":{"mps_collapsed":false,"mps_status":null},"source":["## Support Vector Machines"],"outputs":[],"cell_type":"markdown","execution_count":null},{"id":"c9d7edb5-fc38-470f-b7ce-4ef635372f08","metadata":{"mps_collapsed":false,"mps_is_focused":false,"mps_local_state":{"executionStatus":null,"hiddenOutputs":[],"isNewCell":false},"mps_magic_variables":[],"mps_status":"ok"},"source":["# check if notebook is in colab\n","try:\n","    # install ezkl\n","    import google.colab\n","    import subprocess\n","    import sys\n","    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"ezkl\"])\n","    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"onnx\"])\n","    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"sk2torch\"])\n","\n","# rely on local installation of ezkl if the notebook is not in colab\n","except:\n","    pass\n","\n","# here we create and (potentially train a model)\n","\n","# make sure you have the dependencies required here already installed\n","import json\n","import numpy as np\n","from sklearn.svm import SVC\n","from hummingbird.ml import convert\n","import torch\n","import ezkl\n","import os\n","\n","# Create a dataset of two Gaussians. There will be some overlap\n","# between the two classes, which adds some uncertainty to the model.\n","xs = np.concatenate(\n","    [\n","        np.random.random(size=(256, 2)) + [1, 0],\n","        np.random.random(size=(256, 2)) + [-1, 0],\n","    ],\n","    axis=0,\n",")\n","ys = np.array([False] * 256 + [True] * 256)\n","\n","# Train an SVM on the data and wrap it in PyTorch.\n","sk_model = SVC(probability=True)\n","sk_model.fit(xs, ys)\n","model = convert(sk_model, \"torch\").model\n","\n","model"],"outputs":[{"data":{"text/plain":["Executor(\n","  (_operators): ModuleList(\n","    (0): SVC()\n","  )\n",")"]},"name":null,"metadata":{},"text":null,"execution_count":0,"output_type":"execute_result","traceback":null,"ename":"","evalue":""}],"cell_type":"code","execution_count":null},{"id":"4350eb09-b4ed-4a0c-87b5-c670dd33417f","metadata":{"mps_collapsed":false,"mps_status":"ok"},"source":["model_path = os.path.join('network.onnx')\n","compiled_model_path = os.path.join('network.compiled')\n","pk_path = os.path.join('test.pk')\n","vk_path = os.path.join('test.vk')\n","settings_path = os.path.join('settings.json')\n","\n","witness_path = os.path.join('witness.json')\n","data_path = os.path.join('input.json')"],"outputs":[],"cell_type":"code","execution_count":null},{"id":"39676538-3f8c-4101-acae-d3883b74b409","metadata":{"mps_collapsed":false,"mps_is_focused":false,"mps_local_state":{"executionStatus":null,"hiddenOutputs":[],"isNewCell":false},"mps_magic_variables":[],"mps_status":"ok"},"source":["spaced = np.linspace(-2, 2, num=25)\n","grid_xs = torch.tensor([[x, y] for x in spaced for y in spaced], requires_grad=True)\n","# export to onnx format\n","# !!!!!!!!!!!!!!!!! This will flash a warning but it is fine !!!!!!!!!!!!!!!!!!!!!\n","\n","# Input to the model\n","shape = xs.shape[1:]\n","x = grid_xs[0:1]\n","# Export the model\n","torch.onnx.export(model,               # model being run\n","                  # model input (or a tuple for multiple inputs)\n","                  x,\n","                  # where to save the model (can be a file or file-like object)\n","                  \"network.onnx\",\n","                  export_params=True,        # store the trained parameter weights inside the model file\n","                  opset_version=10,          # the ONNX version to export the model to\n","                  do_constant_folding=True,  # whether to execute constant folding for optimization\n","                  input_names=['input'],   # the model's input names\n","                  output_names=['output'],  # the model's output names\n","                  dynamic_axes={'input': {0: 'batch_size'},    # variable length axes\n","                                'output': {0: 'batch_size'}})\n","\n","d = ((x).detach().numpy()).reshape([-1]).tolist()\n","\n","data = dict(input_data=[d])\n","\n","# Serialize data into file:\n","json.dump(data, open(\"input.json\", 'w'))"],"outputs":[],"cell_type":"code","execution_count":null},{"id":"506493c7-96e2-4b71-9e5f-1c50f9c7e29a","metadata":{"mps_collapsed":false,"mps_is_focused":false,"mps_local_state":{"executionStatus":null,"hiddenOutputs":[],"isNewCell":false},"mps_magic_variables":[],"mps_status":"ok"},"source":["!RUST_LOG=trace\n","# TODO: Dictionary outputs\n","res = ezkl.gen_settings(model_path, settings_path)\n","assert res == True"],"outputs":[],"cell_type":"code","execution_count":null},{"id":"bbff9257-c322-4a74-a879-9b8e01da36b8","metadata":{"mps_collapsed":false,"mps_is_focused":false,"mps_local_state":{"executionStatus":null,"hiddenOutputs":[],"isNewCell":false},"mps_magic_variables":[],"mps_status":"ok"},"source":["cal_path = os.path.join(\"calibration.json\")\n","\n","data_array = ((grid_xs[0:20]).detach().numpy()).reshape([-1]).tolist()\n","\n","data = dict(input_data = [data_array])\n","\n","# Serialize data into file:\n","json.dump(data, open(cal_path, 'w'))\n","\n","await ezkl.calibrate_settings(cal_path, model_path, settings_path, \"resources\")"],"outputs":[{"data":null,"name":"stderr","metadata":{},"text":["Using 3 columns for non-linearity table.\n","Using 6 columns for non-linearity table.\n","Using 11 columns for non-linearity table.\n","Using 11 columns for non-linearity table.\n","[tensor] decomposition error: integer -16865172336 is too large to be represented by base 16384 and n 2\n","forward pass failed: \"failed to forward: [halo2] General synthesis error\"\n","[tensor] decomposition error: integer -133982612098 is too large to be represented by base 16384 and n 2\n","forward pass failed: \"failed to forward: [halo2] General synthesis error\"\n","[tensor] decomposition error: integer -1071671095337 is too large to be represented by base 16384 and n 2\n","forward pass failed: \"failed to forward: [halo2] General synthesis error\"\n","[tensor] decomposition error: integer -267965227070 is too large to be represented by base 16384 and n 2\n","forward pass failed: \"failed to forward: [halo2] General synthesis error\"\n","[tensor] decomposition error: integer -2143342207322 is too large to be represented by base 16384 and n 2\n","forward pass failed: \"failed to forward: [halo2] General synthesis error\"\n","[tensor] decomposition error: integer -4286684401911 is too large to be represented by base 16384 and n 2\n","forward pass failed: \"failed to forward: [halo2] General synthesis error\"\n"," <------------- Numerical Fidelity Report (input_scale: 11, param_scale: 11, scale_input_multiplier: 1) ------------->\n","+------------+--------------+-----------+-----------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n","| mean_error | median_error | max_error | min_error | mean_abs_error | median_abs_error | max_abs_error | min_abs_error | mean_squared_error | mean_percent_error | mean_abs_percent_error |\n","+------------+--------------+-----------+-----------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n","| 0          | 0            | 0         | 0         | 0              | 0                | 0             | 0             | 0                  | 0                  | 0                      |\n","+------------+--------------+-----------+-----------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",""],"execution_count":null,"output_type":"stream","traceback":null,"ename":"","evalue":""},{"data":{"text/plain":["True"]},"name":null,"metadata":{},"text":null,"execution_count":0,"output_type":"execute_result","traceback":null,"ename":"","evalue":""}],"cell_type":"code","execution_count":null},{"id":"7b488b21-0e57-4f71-9de8-5a498df4d574","metadata":{"mps_collapsed":false,"mps_status":"ok"},"source":["res = ezkl.compile_circuit(model_path, compiled_model_path, settings_path)\n","assert res == True"],"outputs":[],"cell_type":"code","execution_count":null},{"id":"0a3c3653-9138-43f2-8a13-079c18d5c7d0","metadata":{"mps_collapsed":false,"mps_status":"ok"},"source":["# srs path\n","res = await ezkl.get_srs( settings_path)"],"outputs":[],"cell_type":"code","execution_count":null},{"id":"86cd510e-bc77-45f8-b428-3053b757eba7","metadata":{"mps_collapsed":false,"mps_status":"ok"},"source":["# now generate the witness file \n","\n","res = await ezkl.gen_witness(data_path, compiled_model_path, witness_path)\n","assert os.path.isfile(witness_path)"],"outputs":[],"cell_type":"code","execution_count":null},{"id":"f8c7177d-f141-443c-93cd-3bb819cab300","metadata":{"mps_collapsed":false,"mps_is_focused":false,"mps_local_state":{"executionStatus":null,"hiddenOutputs":[],"isNewCell":false},"mps_magic_variables":[],"mps_status":"ok"},"source":["# HERE WE SETUP THE CIRCUIT PARAMS\n","# WE GOT KEYS\n","# WE GOT CIRCUIT PARAMETERS\n","# EVERYTHING ANYONE HAS EVER NEEDED FOR ZK\n","\n","res = ezkl.setup(\n","        compiled_model_path,\n","        vk_path,\n","        pk_path,\n","        \n","    )\n","\n","assert res == True\n","assert os.path.isfile(vk_path)\n","assert os.path.isfile(pk_path)\n","assert os.path.isfile(settings_path)"],"outputs":[],"cell_type":"code","execution_count":null},{"id":"2820d7c9-778e-43f4-a454-07eeab89a410","metadata":{"mps_collapsed":false,"mps_is_focused":false,"mps_local_state":{"executionStatus":null,"hiddenOutputs":[],"isNewCell":false},"mps_magic_variables":[],"mps_status":"ok"},"source":["# GENERATE A PROOF\n","\n","proof_path = os.path.join('test.pf')\n","\n","res = ezkl.prove(\n","        witness_path,\n","        compiled_model_path,\n","        pk_path,\n","        proof_path,\n","        \n","        \"single\",\n","    )\n","\n","print(res)\n","assert os.path.isfile(proof_path)"],"outputs":[{"data":null,"name":"stdout","metadata":{},"text":["{'instances': [['0000000000000000000000000000000000000000000000000000000000000000', '0000000000000000000000000000000000000000000000000000000000000000']], 'proof': '0x28544c7c686c05934e140ac62c544b8eaf2cc0c7b6618cd297eb50f2c49e939919ea368afe9b1534e0589053e3437f81987e19f17fb8749af18f065200edfd3b1811b3505d1e7788048e18a351cdb0917626bbfba3fad04cf4012cdb5448a82803220a7cd71fd1e1a61108f570dccccde6cb275b2c785e5d609075827694ded60b1e7e571a3fdae0c796b2b18fd93979c489be32b5f23f50033be7815bde7ead2e81a56727d9bf61ba46fed78a5bbdde6da5ca12ccdd3945da09a972584162fc1a8ba035aea5c501c4907ca2d768bb9588e431182ee091092d4ca37bb5fd1e0624152dc9631883caee5b70e577fedbc006a6f557faf0aa0f55ed069cd49a5c231b36af170facf6651e34306f469331ae30dd4efe155e07e954d046fd88c8ff3c2a58482a4859c306092f1cee2f89f2ec297dac0d3c1a65ec5966ded247bc1c7e2e7d4662d7142c2832b1cffddfab0b444a200f060f6ed70614102bb00b8492660d73b591adebbcd205d33f80a8540968347995545cad944f655b8b68fa8063f101a95e5ba286154d0fce8e4edc467da78ccfbca11412dde607e83d6bee24d65605d4e76c38d2557c3acd536f3b6ccfbada2d7eb95bb3384ff99c6b832f28e32a213824dc8c471b3181ab94c427a816fa5e6e5cc8d7fc704d6657711831ac2ec1108a44b8099ce50374e9c010d59b6b9486ecaf23006d314708e375bf874745841069d0bb23d2b4afaacdbc39e31250c1331aae730aa65e573b88ea6025f9bf2f23f41dbabb4e6a80c9dcd784f5fbda9f354a1fae84ffdaab0258d0e637e4d566098a3088cb767043f485e22a4b0e91935f5712d77813801839533b273642792008e80221c6cefab157631b57f4e44eb22713ecbe5425debeff93f0351c559330217eaaadf0a84753cd2250161c90606b2a0ac3fa8b052855773d0a61074212461862e358e4d9a52c465b244a890f659597b2e24e895a3fc068b33a64e80f7eff19df173926e8ea0087836fc0d37b5cb0342c3562351101accdcd78e0dbdc2e7222c0fd40fd9dd99bcd90d23698e8fc762c2ead499757dcd520447388ef07df6f2f87236e623aca2ac53114725be1d27c185c56f4ddc6e78472d2b32a22ad89d92d793d7b69039ff5dbae801f8f413b05c99825c12a41eb8464ffefcdc42a794a1ac1880e9f55dcbc88e16cd5d10d9a2e4a62ad71e26116a8852834bb0f260f3814654fad59940e5de78244d9e647d932f73c098cb4244e3c529732351c6ade1f2e66f223cc7d960f230b26d0bedcfd5ee1cf8a1378f4c30550f43c82344b78872cf31a3ed5ab271f7d4702fd0232ee7116026b2af8cbaf2b0d55f96cc9cf9a5c19bb1c78430c48874b63e09d0ba266978bb3773e1f885b1ba650c8d219b9d03e2bd5ce12b404521dc2df16b044d1c7b0e0bc0290caf157061456686cc5948e7e0987cec7ddc91f98f5e44167465b7c1c89c2e4db175dc9bd7433b9ebcebd908a1b6e038c9914acda3b0c61e6ecf5cf25a49db51811882265ae4227fe1f91b62e0fa7c5810063032a0ac67203d3fb80825c3c93407cf72e39116367e7fd442c7c2ef3b62d456f35cc1600d71abd95622a7f43b7ac20f2141ddcef59c0d7faea6607d085c3cb2355de073bddeb7d8142337fea6be5b7dfa40b6950816c181f151d1db40a31a3d97e8a68869eb908e7b40f190488f35f2e65e2b0e58d366690c0191a5eb0928be7f88857b046763a6f9d213a176615853137f4674dd443a7f49ec71711b6ddcaf765f0dc432fe3e396ea0f39346ebac1de4eb38789bd765b37c25d1327a29d4c377d2cfc2855ce4a23f0b8eb20a74f5a71174bd2510b557fc084fd2ebf2650d79b8bedc82061cb45281dd7d1f742b1d36a244a8a8c81dde91450df100cdd098a6ea4a0170e7ff89f01907d254da9bab22fe3dbf0179291f31d2cf90692682ce6a4832e165aed12b62a6589784eaf05193d598f2d4eea3c74d9db8f1f53698d3c92385d6bff443cfb2ece52d9b21aae635b75d3d262fe14cb668dd72290a99424abc833ec114bc47b6ef40b07fc4a32d06911d627636dab8b2d91450239414f00c33af36ebeacdb9c9fc0452e8ff7c69f6e5f0216b403a9cedb8af511e8f53a21a166867388b0b7266de3ca71fcbd9766534c48211f850445bf64401736364c0d9b05cf88d8fbe683f0000189f56c5a5db4ce7ea0a783aaefc4f1672f461eb873bc021062d2d1f344449fa236a0c1c73adf836b80dd237db502ca862931a9531cf5bd00fda9368f40f73569ed31a41abf8c759db83c1ee979648e0919f704e62c4631ee6338f44cf24a852588b483ddb3fabc0292f115fa69dd80cc22667b6e0b22193c5f74d3688258c48b7b35dfcc5b6390e264850fbbf71fd15d2dcb62a3356c2e12384addbe21467819fc353e9b2d86eacf865cb52c8b1aeafd1f814e2f76637e2c029185c30e27c0031d4a919adfdde73da99d1314374df89a014fbd51e2445febe135dfb54bb830a3ac2dae183783ae4c25e6613bef435e012e6a00f440433efca72dfb546a312627b16abccf1c4424582a94d85f0291d12f051d802b8ee94e8cab31639ec3896653f66c8334642c8724bd124ee268f652bb12114900a490a45f6919f11baafb617a7312dbf1f8b0ad8c8e56753ec8dbe2bd30039fce3fcd8bf61b06a226333a871e4b7a4800764f511545c1e9e74c4799ab2ab9a7758f7879e6b5d3a56d187ab0dc397b66e9f83068ec5203b226de82b3db0138561e3792fd5a2b1a4469b41bbf3961360d0879a79e51b39e1a5498726b2101c5284877ed905fa6c3695d4fd395dc47e4b520e78d5cdc4717d872b183a7d22da570b21a453540e5269afd8acbc4d95228ef0f641b4f606d9abbde063bf4ef13f0ddb7059aa580146ee1933ba19029ab0787d66ee0ef33d1456549c0f3b1b313f0ddb7059aa580146ee1933ba19029ab0787d66ee0ef33d1456549c0f3b1b325f4708d510274628e794044abc6316a08dbe3f1b55100df1dd1dba453aa622913402a35ecd9c11b8e09934234eb0809037e70f3471b8eba32a02aa9aca6e29728e1d1eaded278a22d0c05cb5290db4c40ade7b8ecb79472802d3517d37036b31636b4c2d3f376c7772bbd851b8ee3ddeeb6ba5575c8a51f18aae89c2219b2b203157f89bc90c2ee3ed16ba4ab88aa698d9e58becc8c771f04145f4d485f189e069925cad8e8cc5b3c574555aa320515450081e9ad0c67dde1fcde22fa1c5cdd083305c04c4efd6a0e7aa63f44c677bb092584030e5519643a7eb477ad06c3b700000000000000000000000000000000000000000000000000000000000000000946661a91db92767aff5f5976e565fa427e8521effd7db90aa3c7b745256e91302034f557d397dd2cc3edf0b36eb2c5e834cb468a14f654183011be7ae8bac70e513dd01cafc1a1076611540cd78bf034c930bdc05ade675a19398fe1868abd0e2c4a9aa043ed9d6611e6a1a269070c3c74907912dc9c94fd9bf4a8b84c7f711363a0e0d0b5926628273b9e56f9c2801ccdb209a92a39f3514f8c14d296b5f308f3ab246ee5fe0d2eb81a0a0a610ba1f3448eb07c287ee2f8fd4d62f294cfa611759ec5fc514ed3ffbcbc4a68258b86dfd9d86447f86136caa263b979da6f3716f8c7a4223ced95ab5940b150603309aca55650f580d0618d5c0640da57ec1612bb3628f795b7204124ad48f0108e5e5d43e63dd2f3dc29cec580077aa8daff19b83a24e2cc43b87d131d23454285ecd3f2754999b7f6bd5a83db8797c848f3209e3eaa304e86b64d972fff53e2cce9416a140ff68a882b953fbc37a6bd94101441ca371a601b1cba03105870d321d5664fea1a78f84ceb3a8605ec5694aa0e23512e2429567f5ce9c6a8e5d0696122bb9b679591d23bc35c7c0b11cc249ff8054b82fbe1fefed626ae3b43f449f1f30cf045b743502b7d4ce500b2a10f1b7604afdf6930c99040525a203dea98e538b9552b020a472b90ed3e7826614da0ca10e39307a04eec2511125d2f5f87b8c447bf8dfe97aca62ebfb4da06e76537d405c03de7b397bb295d966c9b6f91ba393abe4bd4a4f83a3140afa4148d074929298c2202e70679b59899028fb63ead67daeaf42056a88e312f5195338bb942070c58f87c6860f9f56d47d6d584cfd8f7d90711342d300d7532e3211ec6526c85269cf4a1cbda631e33a63a56fd470d9f0bcbea74cc88a4f6e9f66284406e7dac00e58bf2a1f1bd52e5eab51fd60cddb302ab791559c5f2546c5690c14d6dc1fa0f175dd303e9c45f908c9391b02af93abaf32a1bcbf5048a0c2aa94683c8a4de173f46aaaaa7bd11449e7996eed770f3d58021410a0f2cfdac355bfeed3579542ecf8ced4c37792a5c737ef958f8107e1c2c75e97a4d55767ddf0bac1f61b2c50c7892d97dbad829eb395be34acdf9d34668bfeda6ab4e0250de4b842ac231281d70caf8389b568762e97517d49e4f242313724d5528140ac720ed9196f9915401dcfe3a15800a11da4c8b455e19c999717bd3fe5bb5c9f4d5aa8c233bdc0cfe193e268b565b077947f10d876b5f0f56d9fbda3bfbd85954de8364773c1e0d2307f298b73c9ac20f277f8ed2e5ffd1af83930f9bce5dc64654be4f666a792ee20802dd1f6c2047315dcedad4c4e88c87ef119aa52ee5f12c38a5a484eb077e8403871ae206bb9622bdb1c69141906d2342bde5c35df2a1e1e8d815a2759f125d2378cbcf23568982b0c8a17dc29c202d6a2d88c04024ee525c922f872cefd14a2aa3050d166d9c8934bdab1e8d9d078795a0fe6b506b0fbd01d56589e450b1180a9f0a1f3262a2c58afbc6ce211c44c1890c1b155fc2b17fb6a6f73c899f6c0d2b9e4653389b59fc25bc1200078edaad36ddb7ce8770d790409697fb31461aaa1b7f07f9777e0540e4128e096f4c0a8be4bdfe18f239258b2d135ef51f6c707a2cb9d46cdc9e7bbffd42c9d2508edfaf92d0149d01d9645a0fc36fc3bb5f554d0226212b7ec25feee9f30900c098da5490bffe8183949e56a3615380450336000e779cabb9516d35d41929193dd4b65eb7450d3ff3e80c2cf2cbe06877d668872f7f2e43044a5da156ddfe62074fa870335013c81580c6012f3fa10232fd52b5', 'transcript_type': 'EVM'}\n",""],"execution_count":null,"output_type":"stream","traceback":null,"ename":"","evalue":""}],"cell_type":"code","execution_count":null},{"id":"7d2953ca-7f6d-446b-9d6c-04307a4ac658","metadata":{"mps_collapsed":false,"mps_status":"ok"},"source":["# VERIFY IT\n","\n","res = ezkl.verify(\n","        proof_path,\n","        settings_path,\n","        vk_path,\n","        \n","    )\n","\n","assert res == True\n","print(\"verified\")"],"outputs":[{"data":null,"name":"stdout","metadata":{},"text":["verified\n",""],"execution_count":null,"output_type":"stream","traceback":null,"ename":"","evalue":""}],"cell_type":"code","execution_count":null},{"id":"802a3da4-e55a-49b1-a005-5df0b9851f14","metadata":{"mps_collapsed":false,"mps_status":null},"source":["# Linear SVC"],"outputs":[],"cell_type":"markdown","execution_count":null},{"id":"aff2d094-56f0-4425-9545-83c63d99d1b0","metadata":{"mps_collapsed":false,"mps_is_focused":false,"mps_local_state":{"executionStatus":"aborted","hiddenOutputs":[],"isNewCell":false},"mps_magic_variables":[],"mps_status":"ok"},"source":["### Linear SVC\n","\n","# check if notebook is in colab\n","try:\n","    # install ezkl\n","    import google.colab\n","    import subprocess\n","    import sys\n","    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"ezkl\"])\n","    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"onnx\"])\n","    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"sk2torch\"])\n","\n","# rely on local installation of ezkl if the notebook is not in colab\n","except:\n","    pass\n","\n","# here we create and (potentially train a model)\n","\n","# make sure you have the dependencies required here already installed\n","import json\n","import numpy as np\n","from sklearn.svm import LinearSVC\n","import sk2torch\n","import torch\n","import ezkl\n","import os\n","\n","xs = np.concatenate(\n","    [\n","        np.random.random(size=(256, 2)) + [1, 0],\n","        np.random.random(size=(256, 2)) + [-1, 0],\n","    ],\n","    axis=0,\n",")\n","ys = np.array([False] * 256 + [True] * 256)\n","\n","# Train an SVM on the data and wrap it in PyTorch.\n","sk_model = LinearSVC(dual='auto')\n","sk_model.fit(xs, ys)\n","model = sk2torch.wrap(sk_model)"],"outputs":[],"cell_type":"code","execution_count":null},{"id":"fc678a1e-e4a4-4ee7-8519-76206afeb4cc","metadata":{"mps_collapsed":false,"mps_is_focused":false,"mps_local_state":{"executionStatus":"aborted","hiddenOutputs":[],"isNewCell":false},"mps_magic_variables":[],"mps_status":"ok"},"source":["# export to onnx format\n","# !!!!!!!!!!!!!!!!! This will flash a warning but it is fine !!!!!!!!!!!!!!!!!!!!!\n","\n","# Input to the model\n","shape = xs.shape[1:]\n","x = grid_xs[0:1]\n","torch_out = model.predict(x)\n","# Export the model\n","torch.onnx.export(model,               # model being run\n","                  # model input (or a tuple for multiple inputs)\n","                  x,\n","                  # where to save the model (can be a file or file-like object)\n","                  \"network.onnx\",\n","                  export_params=True,        # store the trained parameter weights inside the model file\n","                  opset_version=10,          # the ONNX version to export the model to\n","                  do_constant_folding=True,  # whether to execute constant folding for optimization\n","                  input_names=['input'],   # the model's input names\n","                  output_names=['output'],  # the model's output names\n","                  dynamic_axes={'input': {0: 'batch_size'},    # variable length axes\n","                                'output': {0: 'batch_size'}})\n","\n","d = ((x).detach().numpy()).reshape([-1]).tolist()\n","\n","data = dict(input_shapes=[shape],\n","            input_data=[d],\n","            output_data=[o.reshape([-1]).tolist() for o in torch_out])\n","\n","# Serialize data into file:\n","json.dump(data, open(\"input.json\", 'w'))"],"outputs":[{"data":null,"name":"stderr","metadata":{},"text":["/opt/conda/lib/python3.11/site-packages/sk2torch/linear_model.py:47: TracerWarning:\n","Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",""],"execution_count":null,"output_type":"stream","traceback":null,"ename":"","evalue":""}],"cell_type":"code","execution_count":null},{"id":"2eb9e2cb-be10-493f-be4a-7d9285c80b95","metadata":{"mps_collapsed":false,"mps_status":"ok"},"source":["model_path = os.path.join('network.onnx')\n","compiled_model_path = os.path.join('network.compiled')\n","pk_path = os.path.join('test.pk')\n","vk_path = os.path.join('test.vk')\n","settings_path = os.path.join('settings.json')\n","\n","witness_path = os.path.join('witness.json')\n","data_path = os.path.join('input.json')"],"outputs":[],"cell_type":"code","execution_count":null},{"id":"14beca0e-9101-4a0d-8308-619c07541f9a","metadata":{"mps_collapsed":false,"mps_status":"ok"},"source":["!RUST_LOG=trace\n","# TODO: Dictionary outputs\n","res = ezkl.gen_settings(model_path, settings_path)\n","assert res == True\n","\n","res = await ezkl.calibrate_settings(data_path, model_path, settings_path, \"resources\")\n","assert res == True"],"outputs":[{"data":null,"name":"stderr","metadata":{},"text":["[tensor] decomposition error: integer 279841164 is too large to be represented by base 16384 and n 2\n","forward pass failed: \"failed to forward: [halo2] General synthesis error\"\n","[tensor] decomposition error: integer 279841164 is too large to be represented by base 16384 and n 2\n","forward pass failed: \"failed to forward: [halo2] General synthesis error\"\n"," <------------- Numerical Fidelity Report (input_scale: 13, param_scale: 13, scale_input_multiplier: 1) ------------->\n","+------------+--------------+-----------+-----------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n","| mean_error | median_error | max_error | min_error | mean_abs_error | median_abs_error | max_abs_error | min_abs_error | mean_squared_error | mean_percent_error | mean_abs_percent_error |\n","+------------+--------------+-----------+-----------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n","| 0          | 0            | 0         | 0         | 0              | 0                | 0             | 0             | 0                  | 0                  | 0                      |\n","+------------+--------------+-----------+-----------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",""],"execution_count":null,"output_type":"stream","traceback":null,"ename":"","evalue":""}],"cell_type":"code","execution_count":null}],"nbformat":4,"nbformat_minor":5}